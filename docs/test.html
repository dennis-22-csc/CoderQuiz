<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Large Language Models - CoderQuiz</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 2em; line-height: 1.6; }
        h1 { color: #2c3e50; }
        .question { margin-bottom: 2em; padding: 1em; background: #f9f9f9; border-left: 4px solid #3498db; border-radius: 5px; }
        .options li { margin-bottom: 5px; }
    </style>
</head>
<body>
    <h1>Large Language Models: CoderQuiz</h1>

    <div class="question" id="question347">
        <h2>Question 347</h2>
        <p><strong>What is a transformer architecture primarily designed for?</strong></p>
        <ul class="options">
            <li>A) Image classification</li>
            <li>B) Sequential data processing using recurrence</li>
            <li>C) Capturing long-range dependencies using self-attention</li>
            <li>D) Database indexing</li>
        </ul>
    </div>

    <div class="question" id="question348">
        <h2>Question 348</h2>
        <p><strong>Which component is essential in the self-attention mechanism?</strong></p>
        <ul class="options">
            <li>A) Pooling layer</li>
            <li>B) Query, Key, and Value vectors</li>
            <li>C) Activation function</li>
            <li>D) Dropout layer</li>
        </ul>
    </div>

    <!-- Add more questions here -->

</body>
</html>
