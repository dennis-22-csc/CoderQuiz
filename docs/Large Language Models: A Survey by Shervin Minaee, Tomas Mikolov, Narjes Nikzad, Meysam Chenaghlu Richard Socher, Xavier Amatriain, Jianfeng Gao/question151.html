<!DOCTYPE html>
<html>
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <title>
   Formatted Document
  </title>
  <script async="" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript">
  </script>
  <style>
  </style>
 </head>
 <body>
  <div class="question" id="question151">
   <h2>
    151,What is the main purpose of the Transformer architecture?,To enhance n-gram models,To increase RNN speed,To improve language understanding,To enable parallel computation and efficient training,
   </h2>
   <p>
    âœ…
    <strong>
     To enable parallel computation and efficient training
    </strong>
   </p>
   <h3>
    <strong>
     Explanation:
    </strong>
   </h3>
   <p>
    The Transformer architecture was specifically designed to improve the efficiency of training models by allowing parallel computation, which was not possible with older architectures like RNNs and LSTMs. The use of self-attention mechanisms in Transformers enables models to process entire sequences simultaneously, improving training speed and scalability.
   </p>
  </div>
 </body>
</html>